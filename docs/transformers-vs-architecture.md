# Hugging Face Transformers å’Œ transformeræ¶æ„çš„åŒºåˆ«ï¼Ÿ

## ğŸ—ï¸ Transformer æ¶æ„ - ç†è®ºåŸºç¡€
### æ˜¯ä»€ä¹ˆï¼Ÿ
- ä¸€ç§ç¥ç»ç½‘ç»œæ¶æ„ï¼Œç”±Googleåœ¨2017å¹´ã€ŠAttention Is All You Needã€‹è®ºæ–‡ä¸­æå‡º

- æ ¸å¿ƒåˆ›æ–°ï¼šSelf-Attentionï¼ˆè‡ªæ³¨æ„åŠ›ï¼‰æœºåˆ¶

- è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼šå¤„ç†åºåˆ—æ•°æ®æ—¶çš„é•¿è·ç¦»ä¾èµ–é—®é¢˜

å…³é”®ç»„ä»¶ï¼š

```python
# è¿™ä¸æ˜¯çœŸå®ä»£ç ï¼Œè€Œæ˜¯æ¶æ„æ¦‚å¿µå±•ç¤º
class TransformerArchitecture:
    def __init__(self):
        self.self_attention = MultiHeadAttention()  # å¤šå¤´æ³¨æ„åŠ›
        self.feed_forward = FeedForwardNetwork()    # å‰é¦ˆç½‘ç»œ
        self.layer_norm = LayerNormalization()      # å±‚å½’ä¸€åŒ–
        self.positional_encoding = PositionalEncoding()  # ä½ç½®ç¼–ç 
```

## ğŸ› ï¸ Hugging Face Transformers - è½¯ä»¶å·¥å…·

### æ˜¯ä»€ä¹ˆï¼Ÿ
- ä¸€ä¸ªPythonåº“ï¼Œæä¾›äº†Transformeræ¶æ„çš„å…·ä½“å®ç°

- é¢„è®­ç»ƒæ¨¡å‹ä»“åº“ï¼ŒåŒ…å«æ•°åƒä¸ªåŸºäºTransformerçš„æ¨¡å‹

- å¼€å‘å·¥å…·é›†ï¼Œè®©ä½¿ç”¨è€…æ— éœ€ä»é›¶å¼€å§‹

### æ ¸å¿ƒåŠŸèƒ½

```python
# è¿™æ˜¯ä¸€ä¸ªçœŸå®çš„Hugging Faceä½¿ç”¨ç¤ºä¾‹
from transformers import AutoModel, AutoTokenizer

# ä½¿ç”¨Hugging Faceåº“åŠ è½½ä¸€ä¸ªåŸºäºTransformeræ¶æ„çš„æ¨¡å‹
model = AutoModel.from_pretrained("bert-base-uncased")  # åŸºäºTransformeræ¶æ„
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
```


## ğŸ“Š ç›´è§‚å¯¹æ¯”

| ç»´åº¦ |	Transformer æ¶æ„	| Hugging Face Transformers
|-------|-------|-------|
æ€§è´¨ |	ç†è®ºæ¶æ„	| è½¯ä»¶åº“
è§’è‰² |	è®¾è®¡å›¾çº¸	| å»ºç­‘å…¬å¸
å†…å®¹ |	æ•°å­¦å…¬å¼ã€ç®—æ³•	| ä»£ç ã€é¢„è®­ç»ƒæ¨¡å‹
ä½¿ç”¨ |	éœ€è¦è‡ªå·±å®ç° |	å¼€ç®±å³ç”¨



## ğŸ”„ å…³ç³»å›¾è§£

```text
Transformeræ¶æ„ (ç†è®º)
       â†“
   å„ç§å…·ä½“å®ç°
       â†“
Hugging Face Transformers (å…¶ä¸­ä¸€ä¸ªå®ç°)
       â†“
    BERT, GPT, T5ç­‰å…·ä½“æ¨¡å‹
```

## ğŸ’¡ ä¸¾ä¸ªä¾‹å­
### Transformeræ¶æ„å°±åƒï¼š
- æ±½è½¦å‘åŠ¨æœºåŸç†ï¼ˆå†…ç‡ƒæœºã€ç”µåŠ¨æœºçš„å·¥ä½œåŸç†ï¼‰

### Hugging Face Transformerså°±åƒï¼š
- ä¸°ç”°/ç‰¹æ–¯æ‹‰å…¬å¸ï¼ˆåŸºäºè¿™äº›åŸç†åˆ¶é€ å‡ºå…·ä½“çš„æ±½è½¦å‹å·ï¼‰

### å…·ä½“æ¨¡å‹å°±åƒï¼š
- å‡¯ç¾ç‘/Model 3ï¼ˆå¯ä»¥ç›´æ¥é©¾é©¶çš„æ±½è½¦ï¼‰

## ğŸŒŸ å®é™…å…³ç³»ä½“ç°

```python
# å½“ä½ ä½¿ç”¨Hugging Faceæ—¶ï¼Œå…¶å®æ˜¯åœ¨ä½¿ç”¨åŸºäºTransformeræ¶æ„çš„æ¨¡å‹
from transformers import BertModel  # BERTåŸºäºTransformerç¼–ç å™¨æ¶æ„
from transformers import GPT2Model  # GPTåŸºäºTransformerè§£ç å™¨æ¶æ„

# è¿™äº›æ¨¡å‹éƒ½ä½¿ç”¨äº†Transformeræ¶æ„çš„ç»„ä»¶ï¼š
# - è‡ªæ³¨æ„åŠ›æœºåˆ¶
# - å±‚å½’ä¸€åŒ–  
# - å‰é¦ˆç½‘ç»œ
# - æ®‹å·®è¿æ¥
```

## ğŸ¯ æ€»ç»“åŒºåˆ«
- Transformeræ¶æ„æ˜¯ç†è®ºï¼Œæ˜¯è®¾è®¡æ€æƒ³

- Hugging Face Transformersæ˜¯å®è·µï¼Œæ˜¯å·¥å…·é›†åˆ

- Hugging Face å®ç°äº†Transformeræ¶æ„ï¼Œå¹¶è®©æ‰€æœ‰äººéƒ½èƒ½è½»æ¾ä½¿ç”¨

ç®€å•è¯´ï¼šTransformeræ˜¯æƒ³æ³•ï¼ŒHugging Faceæ˜¯å®ç°è¿™ä¸ªæƒ³æ³•çš„å·¥å…·ï¼